{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
                "os.environ[\"HF_HOME\"] = str(Path.cwd().joinpath(\"cache\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Model and Scheduler by EDM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from diffusers import DiffusionPipeline\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "from diffusers.utils import make_image_grid\n",
                "from IPython import get_ipython\n",
                "from IPython.display import display\n",
                "from PIL import Image\n",
                "import torch\n",
                "\n",
                "sys.path.append(Path(get_ipython().run_line_magic(\"pwd\", \"\")).resolve().parent.as_posix())\n",
                "\n",
                "from coach_pl.configuration import CfgNode\n",
                "from coach_pl.model import build_model\n",
                "from coach_pl.utils.checkpoint import load_pretrained\n",
                "\n",
                "from diffusion.module.scheduler import (\n",
                "    EDMNoiseScheduler,\n",
                "    RectifiedFlowNoiseScheduler,\n",
                ")\n",
                "from image import (\n",
                "    EDMPipeline,\n",
                "    MeanFlowPipeline,\n",
                "    RectifiedFlowPipeline,\n",
                ")\n",
                "\n",
                "ROOT = Path(get_ipython().run_line_magic(\"pwd\", \"\")).resolve().parent\n",
                "CONFIGURATION_PATH = ROOT.joinpath(\"diffusion/configuration\")\n",
                "CHECKPOINT_PATH = ROOT.joinpath(\"output\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def draw_inference_result(\n",
                "    pipeline: DiffusionPipeline,\n",
                "    grid_size: int,\n",
                "    num_inference_steps: int,\n",
                "    seed: int\n",
                ") -> None:\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    samples = pipeline(output_shape=(grid_size ** 2, 3, 32, 32), num_inference_steps=num_inference_steps)\n",
                "    samples = ((samples + 1.0) * 127.5).clip(0, 255).byte().detach().cpu().numpy()\n",
                "    images = samples.transpose(0, 2, 3, 1)\n",
                "    images = list(Image.fromarray(image) for image in images)\n",
                "    display(make_image_grid(images, grid_size, grid_size))\n",
                "\n",
                "def draw_inference_result_condition(\n",
                "    pipeline: DiffusionPipeline,\n",
                "    grid_size: int,\n",
                "    num_inference_steps: int,\n",
                "    condition: int,\n",
                "    seed: int\n",
                ") -> None:\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    samples = pipeline(output_shape=(grid_size ** 2, 3, 32, 32), num_inference_steps=num_inference_steps, condition=condition)\n",
                "    samples = ((samples + 1.0) * 127.5).clip(0, 255).byte().detach().cpu().numpy()\n",
                "    images = samples.transpose(0, 2, 3, 1)\n",
                "    images = list(Image.fromarray(image) for image in images)\n",
                "    display(make_image_grid(images, grid_size, grid_size))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = 0\n",
                "grid_size = 8\n",
                "num_inference_steps = 32\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cfg_unconditional = CfgNode.load_yaml_with_base(CONFIGURATION_PATH.joinpath(\"edm_unet_cifar.yaml\"))\n",
                "cfg_conditional = CfgNode.load_yaml_with_base(CONFIGURATION_PATH.joinpath(\"edm_unet_cifar.yaml\"))\n",
                "CfgNode.merge_with_dotlist(cfg_unconditional, [\"MODEL.NUM_CLASSES\", 0])\n",
                "CfgNode.set_readonly(cfg_unconditional, True)\n",
                "CfgNode.set_readonly(cfg_conditional, True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test Rectified Flow's Formulation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unconditional = build_model(cfg_unconditional).eval()\n",
                "load_pretrained(model_unconditional, CHECKPOINT_PATH.joinpath(\"rectified_flow/velocity_unet_cifar_unconditional/regular_ckpts/last.ckpt\"))\n",
                "model_conditional = build_model(cfg_conditional).eval()\n",
                "load_pretrained(model_conditional, CHECKPOINT_PATH.joinpath(\"rectified_flow/velocity_unet_cifar_conditional/regular_ckpts/last.ckpt\"))\n",
                "\n",
                "scheduler = RectifiedFlowNoiseScheduler(\n",
                "    t_min=0.0001,\n",
                "    t_max=0.9999,\n",
                "    sigma_data=cfg_unconditional.MODULE.NOISE_SCHEDULER.SIGMA_DATA,\n",
                "    prediction_type=\"velocity\",\n",
                "    algorithm_type=\"ode\",\n",
                "    timestep_schedule=\"uniform\"\n",
                ")\n",
                "\n",
                "pipeline_unconditional = RectifiedFlowPipeline(model_unconditional, scheduler).to(device)\n",
                "pipeline_conditional = RectifiedFlowPipeline(model_conditional, scheduler).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "draw_inference_result(pipeline_unconditional, grid_size, num_inference_steps, seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for c in torch.arange(10, device=device):\n",
                "    draw_inference_result_condition(pipeline_conditional, grid_size, num_inference_steps, c, seed)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test EDM's Formulation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unconditional = build_model(cfg_unconditional).eval()\n",
                "load_pretrained(model_unconditional, CHECKPOINT_PATH.joinpath(\"edm/sample_unet_cifar_unconditional/regular_ckpts/last.ckpt\"))\n",
                "model_conditional = build_model(cfg_conditional).eval()\n",
                "load_pretrained(model_conditional, CHECKPOINT_PATH.joinpath(\"edm/sample_unet_cifar_conditional/regular_ckpts/last.ckpt\"))\n",
                "\n",
                "scheduler = EDMNoiseScheduler(\n",
                "    t_min=0.002,\n",
                "    t_max=80.0,\n",
                "    sigma_data=cfg_unconditional.MODULE.NOISE_SCHEDULER.SIGMA_DATA,\n",
                "    prediction_type=\"sample\",\n",
                "    algorithm_type=\"ode\",\n",
                "    timestep_schedule=\"linear_lognsr\"\n",
                ")\n",
                "\n",
                "pipeline_unconditional = EDMPipeline(model_unconditional, scheduler).to(device)\n",
                "pipeline_conditional = EDMPipeline(model_conditional, scheduler).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "draw_inference_result(pipeline_unconditional, grid_size, num_inference_steps, seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for c in torch.arange(10, device=device):\n",
                "    draw_inference_result_condition(pipeline_conditional, grid_size, num_inference_steps, c, seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unconditional = build_model(cfg_unconditional).eval()\n",
                "load_pretrained(model_unconditional, CHECKPOINT_PATH.joinpath(\"edm/epsilon_unet_cifar_unconditional/regular_ckpts/last.ckpt\"))\n",
                "model_conditional = build_model(cfg_conditional).eval()\n",
                "load_pretrained(model_conditional, CHECKPOINT_PATH.joinpath(\"edm/epsilon_unet_cifar_conditional/regular_ckpts/last.ckpt\"))\n",
                "\n",
                "scheduler = EDMNoiseScheduler(\n",
                "    t_min=0.002,\n",
                "    t_max=80.0,\n",
                "    sigma_data=cfg_unconditional.MODULE.NOISE_SCHEDULER.SIGMA_DATA,\n",
                "    prediction_type=\"epsilon\",\n",
                "    algorithm_type=\"ode\",\n",
                "    timestep_schedule=\"linear_lognsr\"\n",
                ")\n",
                "\n",
                "pipeline_unconditional = EDMPipeline(model_unconditional, scheduler).to(device)\n",
                "pipeline_conditional = EDMPipeline(model_conditional, scheduler).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "draw_inference_result(pipeline_unconditional, grid_size, num_inference_steps, seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for c in torch.arange(10, device=device):\n",
                "    draw_inference_result_condition(pipeline_conditional, grid_size, num_inference_steps, c, seed)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test Mean Flow's Formulation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unconditional = build_model(cfg_unconditional).eval()\n",
                "load_pretrained(model_unconditional, CHECKPOINT_PATH.joinpath(\"mean_flow/velocity_unet_cifar_unconditional/regular_ckpts/last.ckpt\"))\n",
                "model_conditional = build_model(cfg_conditional).eval()\n",
                "load_pretrained(model_conditional, CHECKPOINT_PATH.joinpath(\"mean_flow/velocity_unet_cifar_conditional/regular_ckpts/last.ckpt\"))\n",
                "\n",
                "scheduler = RectifiedFlowNoiseScheduler(\n",
                "    t_min=0.0,\n",
                "    t_max=1.0,\n",
                "    sigma_data=cfg_unconditional.MODULE.NOISE_SCHEDULER.SIGMA_DATA,\n",
                "    prediction_type=\"velocity\",\n",
                "    algorithm_type=\"ode\",\n",
                "    timestep_schedule=\"uniform\"\n",
                ")\n",
                "\n",
                "pipeline_unconditional = MeanFlowPipeline(model_unconditional, scheduler).to(device)\n",
                "pipeline_conditional = MeanFlowPipeline(model_conditional, scheduler).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "draw_inference_result(pipeline_unconditional, grid_size, 4 + 1, seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for c in torch.arange(10, device=device):\n",
                "    draw_inference_result_condition(pipeline_conditional, grid_size, 4 + 1, c, seed)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "diffusion",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
